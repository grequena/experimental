---
output: html_document
editor_options: 
  chunk_output_type: console
---
# Delineamento Inteiramente Casualizado {#dic}

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

#libraries
library(kableExtra)
library(tidyverse)
```

O *delineamento inteiramente casualizado (DIC)*, como visto anteriormente, é preferido quando as unidades experimentais são homogêneas entre si em suas principais características (que podem influenciar na variável resposta).

Tal delineamento se dá quando os tratamentos (ou níveis de um fator) são distribuídos **totalmente ao acaso** dentre as unidades experimentais.

Veremos adiante que há diferentes esquemas para se construir tratamentos, como em experimentos fatoriais e em parcelas subdivididas, porém, neste capítulo, trabalhamos apenas com um fator.

::: {.example #dic} 
_Temos $N=9$ sementes de feijão e $a=3$ níveis de irrigação (A, B, C) e iremos medir o peso em gramas da planta, após determinado tempo._

_O DIC pode ser construido enumerando as sementes de 1 a 9 e sorteando aleatoriamente os tratamentos._

_É possível realizar este sorteio no R de diferentes maneiras. Uma delas é através da função `sample`._
:::

<details> <summary><span style="color:blue">Código em R com resultado</span></summary>
```{r, include=FALSE}
set.seed(321)
```
```{r, results='hide'}
N=9 #n. de unidades experimentais
a=3 #n. de tratamentos
n=3 #n. de repetições
sorteio <- sample(x=rep(LETTERS[1:a],n), size=N, replace=F)
print(data.frame("semente"=1:N,"tratamento"=sorteio))
```
```{r, echo=FALSE}
tab <- tibble("semente"=1:N, "tratamento"=sorteio)
kable(tab, align='c')
```
<hr style="width:5%">
</details>
<p style="text-align:right;">$\square$</p>

Neste exemplo, a pergunta que surge é: existe algum nível de irrigação (tratamento) que é melhor do que os demais? Em outras palavras: os tratamentos são diferentes entre si?

Estatisticamente falando, estamos estabelecendo hipóteses nula e alternativa:
\begin{align*}
H_0: & \mu_1=\mu_2=\mu_3\\
H_1: & \mu_1\neq \mu_2 \text{ ou }\mu_1\neq \mu_3 \text{ ou }\mu_2\neq \mu_3
\end{align*}


Sob alguns pressupostos, hipóteses deste tipo podem ser testadas utilizando a **análise de variância**, denominada **ANOVA** (do inglês: **an**alysis **o**f **va**riance), que discutimos a seguir.



<!-- ------------------------------------------------------------ -->



## ANOVA

Nesta seção, descrevemos como realizar análise de variância para o DIC. Dividimos esta seção em:

- [Modelo estatístico]
- [Pressupostos]
- [Modelo de efeitos]
- [Hipóteses]
- [Por que analisar variância para comparar médias?] 

Como estamos trabalhando apenas com um único fator, o que desenvolvemos nesta seção leva o nome **ANOVA _ONE-WAY_** ou, também, **ANOVA DE FATOR ÚNICO**.

Para prosseguir, suponha que temos:

- $a$ tratamentos (ou níveis de um fator)
- $n$ repetições em cada tratamento
- $N=na$ unidades experimentais,
ou seja, estamos supondo que o DIC seja balanceado (mesmo número de repetições em cada tratamento)

<!-- ----------------------------------------------- -->

### Modelo estatístico

Um modelo estatístico tem como objetivo descrever matematicamente um fenômeno aleatório do mundo real. Com isso, há suposições que são consideradas, uma vez que se trata de uma aproximação matemática da realidade.

"A realidade é muito mais complexa do que qualquer modelo matemático."

> O **modelo estatístico do DIC** é escrito por:
\begin{equation}
  y_{ij}=\mu_i+\epsilon_{ij}
  (\#eq:modelodic)
\end{equation}
em que:
> 
- $i$ é o índice do tratamento, variando em $1, 2, ..., a$
- $j$ é o índice da repetição em cada tratamento, variando em $1, 2, ..., n$
- $y_{ij}$ é a observação $j$ do tratamento $i$ da variável resposta $y$
- $\mu_i$ é a média (populacional) do tratamento $i$
- $\epsilon_{ij}$ é o  erro aleatório da observação $j$ do tratamento $i$ (incorpora todas as fontes de variação que vão além da variação entre os tratamentos)

Este modelo nos diz que cada observação é igual a média populacional do respectivo tratamento mais um erro aleatório individual. 

Estamos considerando que $\mu_i$ é uma quantidade numérica fixa da população (a "verdadeira média"), porém, por se tratar de um **parâmetro**, é desconhecida e não observável e, além disso, é nela que temos interesse em fazer inferência.

O componente aleatório deste modelo é o erro $\epsilon_{ij}$, que é individual, isto é, para cada observação $j$ de cada tratamento $i$. 

::: {.example}

_Utilizando o Exemplo \@ref(exm:dic), vamos supor, hipoteticamente, que você consultou um oráculo e sabe as médias populacionais dos $a=3$ níveis de irrigação. Considere que são:_
\begin{align}
\mu_1=30\\
\mu_2=40\\
\mu_3=50
\end{align}

_Se observamos as $n=3$ repetições no tratamento $1$ como: $y_{11}=33, y_{12}=31, y_{13}=25$; então, a partir do modelo da Equação \@ref(eq:modelodic), temos que:_
\begin{align}
y_{11}=\mu_1+\epsilon_{11} & \Leftrightarrow  33=30+(-3)\\
y_{12}=\mu_1+\epsilon_{12} & \Leftrightarrow  31=30+1\\
y_{13}=\mu_1+\epsilon_{13} & \Leftrightarrow  25=30+(-5)
\end{align}

_Note que, as médias populacionais, na prática, são desconhecidas. Temos acesso apenas as observações $y_{ij}$ e realizar **inferência estatística** é, a partir destas observações, estimar as médias populacionais. Uma estimativa "natural" para a média populacional é a média amostral._

_Os erros aleatórios também não são observáveis, uma vez que $\epsilon_{ij}=y_{ij}-\mu_i$. No exemplo, $\epsilon_{11}=-3, \epsilon_{12}=1 \text{ e } \epsilon_{13}=-5$._

_Iremos definir e lidar com os resíduos do modelo em seção subsequente._
<p style="text-align:right;">$\square$</p>
:::

<!-- ----------------------------------------------- -->

### Pressupostos {#pressupostos}

Para dar seguimento com as análises estatísticas, precisamos fazer algumas suposições com relação ao modelo estatístico apresentado, que são razoáveis em grande parte das aplicações.

A principal suposição é que:
\begin{equation}
\epsilon_{ij}\overset{ind}{\sim}N(0, \sigma^2)
(\#eq:pressuposto)
\end{equation}
em que $i=1, 2, ..., a; j=1, 2, ..., n.$ 

Lemos a expressão acima como: os erros são independentes e identicamente distribuídos, com distribuição normal com média zero e variância sigma dois".

Vamos dividir tal suposição em 4 pressupostos do modelo:

1) **Os erros têm média zero**, i.e. $E(\epsilon_{ij})=0.$ Este pressuposto é relativamente intuitivo: as observações da variável resposta $y$ no tratamento $i$ são aleatórias em torno da respectiva média.
2) **Os erros têm distribuição normal**. Este pressuposto requer que a variável resposta seja aleatória com distribuição normal. O modelo   diz que $y_{ij}=\mu_i+\epsilon_{ij}$ e como $\epsilon$ é normal, então $y$ também é. Logo, é análogo supor que a variável resposta $y$ seja normal. Isto se aplica a inúmeros exemplos e geralmente a variável resposta deve ser contínua, simétrica, com uma variabilidade razoável (sem muitos empates). Comprimento e peso são exemplo clássicos de aplicações.  
3) **Os erros têm variâncias iguais** para todos os tratamentos, i.e. $\sigma^2_1=\sigma^2_1=\cdots =\sigma^2_a=\sigma^2$. Este pressuposto leva o nome de **homocedasticidade** (homogeneidade das variâncias). Caso alguma variância seja diferente, dizemos que há **heretocedasticidade**.
4) **Os erros são independentes**, i.e. as unidades experimentais devem ser independentes entre si. Em outras palavras, a observação de uma unidade não está associada a observação de outra unidade qualquer.

Veremos como verificar os pressupostos em seção subsequente.

A suposição da Equação \@ref(eq:pressuposto) é equivalente a:
$$y_{ij}\overset{ind}{\sim}N(\mu_i, \sigma^2)$$
em que $i=1, 2, ..., a; j=1, 2, ..., n,$ uma vez que
\begin{align}
E(y_{ij})&=E(\mu_i+\epsilon_{ij})=E(\mu_i)+E(\epsilon_{ij})=\mu_i+0=\mu_i\\
var(y_{ij})&=var(\mu_i+\epsilon_{ij})=var(\mu_i)+var(\epsilon_{ij})=0+\sigma^2=\sigma^2
\end{align}

<!-- ----------------------------------------------- -->

### Modelo de efeitos

Um modelo alternativo para o DIC bastante utilizado é o modelo de efeitos.

> O **modelo estatístico de efeitos do DIC** pode ser escrito por:
\begin{equation}
  y_{ij}=\mu+\tau_i+\epsilon_{ij}
  (\#eq:modelodic2)
\end{equation}
em que i=1,2, ..., a; j=1, 2, ..., n; $y_{ij}$ e $\epsilon_{ij}$ são idênticos ao modelo de médias \@ref(eq:modelodic); e:
> 
- $\mu$ é uma média (populacional) global;
- $\tau_i$ é o efeito do tratamento $i$ (que pode ser positivo, negativo ou nulo).

Este modelo é equivalente ao modelo de médias, mas pode trazer interpretações diferentes:

- $\mu$ representa uma média geral, independente do tratamento
- a média do tratamento $i$ pode ser escrita por $\mu_i=\mu+\tau_i$
- o efeito $\tau_i$ é o que possivelmente diferencia a média de um tratamento do outro
- se o efeito de $\tau_i$ é positivo, a média do tratamento $i$ está acima da média global; caso seja negativo, a média $\mu_i$ está abaixo de $\mu$; caso o efeito seja nulo $\mu_i=\mu$
- se todos os efeitos são nulos, então $\mu_i=\mu, i=1, 2, ..., a$, ou seja, $\mu_1=\mu_2=\cdots \mu_a=\mu$
- os efeitos $\tau_i$ também são parâmetros e, portanto, temos interesse em fazer inferência, uma vez que são reponsáveis por diferenciar um tratamento do outro
- é razoável considerar que $\tau_1+\tau_2+\cdots =\tau_a=0$. Isto faz com que a média global $\mu$ seja uma média das médias populacionais (muita média em uma mesma frase, o que pode ser confuso), ou seja:
$$\frac{1}{a}\sum_{i=1}^a\mu_i=\frac{1}{a}\sum_{i=1}^a(\mu+\tau_i)=\frac{1}{a} \left( \sum_{i=1}^a\mu+\sum_{i=1}^a\tau_i \right) =\frac{1}{a}a\mu+0=\mu$$

<!-- ----------------------------------------------- -->

### Hipóteses

O modelo de médias nos diz que $y_{ij}=\mu_i+\epsilon_{ij}$. Os parâmetros que desejamos fazer inferência são as médias de cada tratamento. Assim, a hipótese a ser testada pela ANOVA é:
\begin{equation}
\begin{split}
H_0: & \mu_1=\mu_2=\cdots =\mu_a\\
H_1: & \mu_i\neq \mu_j, \text{ para algum } i\neq j
\end{split}
(\#eq:hipanova)
\end{equation}

Note que, a hipótese alternativa nos diz que basta uma das médias ser diferente das demais para que $H_0$ seja falsa.

Note que:
\begin{align}
\mu_1=\mu_2=\cdots =\mu_a &\Leftrightarrow \mu+\tau_1=\mu+\tau_2=\cdots =\mu+\tau_a\\
&\Leftrightarrow \tau_1=\tau_2=\cdots =\tau_a\\
&\Leftrightarrow \tau_1=\tau_2=\cdots =\tau_a=0
\end{align}
A terceira linha desta relação vem do fato que vimos anteriormente, que $\tau_1+\tau_2+\cdots +\tau_a=0$, e se $\tau_1=\tau_2=\cdots =\tau_a$, então a única possibilidade é $\tau_1=\tau_2=\cdots =\tau_a=0$.

Dado isso, as hipóteses dadas pela Equação \@ref(eq:hipanova) são equivalentes a:
\begin{equation}
\begin{split}
H_0: & \tau_1=\tau_2=\cdots =\tau_a=0\\
H_1: & \tau_i\neq 0, \text{ para algum } i
\end{split}
\end{equation}
Note que, basta que algum $\tau_i$ seja diferente de zero para que $H_0$ seja falsa.

<!-- ----------------------------------------------- -->

### Por que analisar variância para comparar médias?

Quando temos apenas dois tratamentos, a hipótese nula a ser testada é $H_0: \mu_1=\mu_2$. 
Sob o pressuposto de normalidade, podemos testar tal hipótese com o teste t e não precisamos da ANOVA.

O teste t utiliza como estatística de teste, considerando tamanhos amostrais iguais ($n_1=n_2$) e variâncias iguais ($\sigma^2_1=\sigma^2_2$), a seguinte:
$$t=\frac{\bar{y}_1-\bar{y}_2}{\sqrt{(S^2_1+S^2_2)/n}}$$
em que:

- t tem distribuição t-Student com $2n-2$ graus de liberdade
- $\bar{y}_1$ e $\bar{y_2}$ são as médias amostrais dos tratamentos 1 e 2, respectivamente
- $S_1^2$ e $S_2^2$ são as variâncias amostrais dos tratamentos 1 e 2, respectivamente

O importante neste momento é notar que o valor absoluto da estatística $|t|$ mede uma distância padronizada entre as médias amostrais. 
<details> <summary><span style="color:blue">Leia mais</span></summary>

Em resumo, se $|t|$ for "muito" grande, isso significa que $\bar y_1$ está "muito" distante de $\bar y_2$, trazendo evidência contra $H_0:\mu_1=\mu_2$. 

Note que, com um nível de significância $\alpha$, determinamos o quantil (t tabelado), digamos $t_{\alpha,2n-2}$, que nos dá um ponto de corte para considerar o que queremos dizer com $|t|$ ser "muito" grande. Ou seja, se $|t| > t_{\alpha,2n-2}$, então $\bar{y}_1$ está longe o suficiente de $\bar{y}_2$, o que nos leva a crer (por meio de evidências) que $\mu_1\neq \mu_2$, nos levando a rejeitar $H_0$.

<hr style="width:5%">
</details>

Pergunta: é possível medir uma distância entre 3 médias de tratamentos para concluir se há evidências o suficiente para rejeitar $H_0:\mu_1=\mu_2=\mu_3$, com um nível de significância $\alpha$?

A resposta para esta pergunta não é tão trivial. Uma resposta está em analisar as variâncias. 

Considere o seguinte exemplo, para compreender o porque analisar variâncias é útil para comparar médias de 3 ou mais tratamentos.

::: {.example} 
<i>
Considere dois cenários, ambos com $a=4$ tratamentos e $n=10$ repetições em cada tratamento, totalizando $N=40$ unidades experimentais.

Vamos simular dados para o cenário A e B, seguindo os pressupostos da subseção [Pressupostos], em que:

- no cenário A há diferença entre as médias;
- no cenário B **não** há diferença entre as médias.

Os dados em ambos os cenários estão representados nos gráficos de dispersão abaixo.

(ref:foo-1) Gráfico de dispersão dos cenários A e B, respectivamente. O ponto vermelho representa a média amostral em cada tratamento. A última coluna representa todos os dados, independente do tratamento.

```{r foo-1, echo=FALSE, fig.cap='(ref:foo-1)'}
set.seed(2468)
n <- 10;a <- 4
trat <- 1:a |> rep(n) |> sort()
total <- rep(5,n*a)
trat <- c(trat,total)

m1 <- 10;m2 <- 20;m3 <- 30;m4 <- 40
y1 <- rnorm(n, m1, 2);y2 <- rnorm(n, m2, 2)
y3 <- rnorm(n, m3, 2);y4 <- rnorm(n, m4, 2)
y <- rep(c(y1,y2,y3,y4),2)
d1 <- tibble(y,trat)

m <- 25
w1 <- rnorm(n, m, 2);w2 <- rnorm(n, m, 2)
w3 <- rnorm(n, m, 2);w4 <- rnorm(n, m, 2)
w <- rep(c(w1,w2,w3,w4),2)
d2 <- tibble(w,trat)

p1 <- d1 |> 
  ggplot(aes(x=trat, y=y)) + 
  geom_point(shape=4) +
  stat_summary(
    geom = "point",
    fun = "mean",
    col = "red",
    size = 2,
    shape = 19
  ) +
  labs(title="Cenário A",
       x="Tratamento", 
       y="Variável Resposta") +
  theme(axis.text.y = element_blank())+
  scale_x_continuous(breaks=1:5,
                   labels=c("Trat 1","Trat 2","Trat 3",
                            "Trat 4","Total"))

p2 <- d2 |> 
  ggplot(aes(x=trat, y=w)) + 
  geom_point(shape=4) +
  stat_summary(
    geom = "point",
    fun = "mean",
    col = "red",
    size = 2,
    shape = 19
  ) +
  labs(title="Cenário B",
       x="Tratamento", 
       y="Variável Resposta") +
  theme(axis.text.y = element_blank())+
  scale_x_continuous(breaks=1:5,
                   labels=c("Trat 1","Trat 2","Trat 3",
                            "Trat 4","Total"))

gridExtra::grid.arrange(p1, p2, ncol=2)
```

Podemos ver na Figura \@ref(fig:foo-1) que de fato o cenário A é diferente do B no que diz respeito às médias; no cenário A as médias amostrais dos tratamentos de 1 a 4 (primeiras 4 colunas) são bem diferentes entre si e no cenário B são similares 

Mas observe a dispersão (variância) em cada um dos 4 tratamentos. Em ambos os cenários as dispersões entre os tratamentos são similares entre si. Agora observe a dispersão do total (última coluna):

- no cenário A, as dispersões dos tratamentos são **diferentes** da dispersão total
- no cenário B, as dispersões dos tratamentos são **similares**  da dispersão total

Isso nos leva a crer na seguinte afirmação:

> se as variâncias dos tratamentos são diferentes da variância total dos dados, então as médias são diferentes entre si.

</i>
:::

<i>
<details> <summary><span style="color:blue">Leia mais</span></summary>
Vamos colocar em termos numéricos estas diferenças. As variâncias amostrais de ambos os cenários são organizadas na tabela abaixo.
```{r echo=FALSE}
vary <- d1 |> group_by(trat) |> summarise(sd(y)) |> select(2) |> as_vector()
varw <- d2 |> group_by(trat) |> summarise(sd(w)) |> select(2) |> as_vector()

tab <- rbind(t(vary),t(varw))
colnames(tab) <- c("$S^2_1$","$S^2_2$","$S^2_3$",
                   "$S^2_4$","$S^2_{Total}$")
rownames(tab) <- c('Cenário A', 'Cenário B')
kable(tab, digits=2)
```

Ao analisar as primeiras 4 colunas (tratamentos) com a última (total), confirmamos que:

- as variâncias dos tratamentos são similares entre si (o que, vale ressaltar, nos leva a crer que o pressuposto de homocedasticidade é válido)
- as variâncias dos tratamentos são diferentes da variância total no cenário A, mas similar no cenário B

Podemos mensurar esta diferença, fazendo uma variância média dos tratamentos e comparar com a total. Considere a variância média como:
$$\overline{S^2}=\frac{1}{a}\sum_{i=1}^aS^2_i$$
e podemos considerar o ganho relativo na variância, obtido ao se considerar os tratamentos, isto é: 
$$R^2=\frac{S^2_{Total}-\overline{S^2}}{S^2_{Total}}$$
Em outras palavras, o $R^2$ mede o quanto a variância total reduziu quando estamos considerando o tratamento que cada observação pertence. Não precisamos interpretá-lo a fundo agora, até porque construiremos outra medida que chamaremos de $F$. A medida $R^2$ é conhecida na Estatística e leva o nome de coeficiente de determinação. 

O que precisamos saber no momento é que $0\leq R^2 \leq 1$ e quanto mais próximo de 1, mas diferente são $S^2_{Total}$ e $\overline{S^2}$ e quanto mais próximo de 0, mais próximos são $S^2_{Total}$ e $\overline{S^2}$.

No cenário A, esta medida é igual a `r round(1-(mean(tab[1,1:4])/tab[1,5]),1)` e no cenário B é igual a `r round(1-(mean(tab[2,1:4])/tab[2,5]),1)`. Podemos interpretar da seguinte maneira:

- no cenário A, 80% da variabilidade dos dados foi explicada pelos tratamentos, tornando os tratamentos um aspecto importante para explicar a variável resposta
- no cenário B, 0% da variabilidade dos dados foi explicada pelos tratamenos, o que mostra a irrelevância dos tratamentos para explicar a variável respota
<hr style="width:5%">
</details>
</i>
<p style="text-align:right;">$\square$</p>

Em subseção subsequente, construímos uma medida parecida com esta razão que terá distribuição F e, assim, podemos utilizar o teste F para analisar tais variâncias e concluir se há evidências favoráveis ou contrárias à igualdade das médias.
</i>


<!-- ----------------------------------------------- -->

### Soma de quadrados

A principal ideia da ANOVA é particionar a variabilidade total dos dados em diferentes fontes de variação. No caso do DIC, há apenas duas possíveis, os **tratamentos** e o **erro**, que variabilidades naturais das unidades experimentais e de outros fatores não controlados.

Para compreender tal partição, considere a notação a seguir. Considere que a tabela abaixo representa as observações da variável resposta $y$.

<style type="text/css">
.tg  {border-collapse:collapse;border-spacing:0;}
.tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;
  overflow:hidden;padding:10px 5px;word-break:normal;}
.tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;
  font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}
.tg .tg-baqh{text-align:center;vertical-align:top}
.tg .tg-amwm{font-weight:bold;text-align:center;vertical-align:top}
</style>
<table class="tg">
<thead>
  <tr>
    <th class="tg-amwm"></th>
    <th class="tg-amwm" colspan="4">Repetições</th>
    <th class="tg-amwm"></th>
    <th class="tg-amwm"></th>
  </tr>
</thead>
<tbody>
  <tr>
    <td class="tg-amwm">Tratamento</td>
    <td class="tg-amwm">1</td>
    <td class="tg-amwm">2</td>
    <td class="tg-amwm">$\cdots$</td>
    <td class="tg-amwm">n</td>
    <td class="tg-amwm">Totais</td>
    <td class="tg-amwm">Médias</td>
  </tr>
  <tr>
    <td class="tg-amwm">1</td>
    <td class="tg-baqh">$y_{11}$</td>
    <td class="tg-baqh">$y_{12}$</td>
    <td class="tg-baqh">$\cdots$</td>
    <td class="tg-baqh">$y_{1n}$</td>
    <td class="tg-baqh">$y_{1\cdot}$</td>
    <td class="tg-baqh">$\overline{y}_{1\cdot}$</td>
  </tr>
  <tr>
    <td class="tg-amwm">2</td>
    <td class="tg-baqh">$y_{21}$</td>
    <td class="tg-baqh">$y_{22}$</td>
    <td class="tg-baqh">$\cdots$</td>
    <td class="tg-baqh">$y_{2n}$</td>
    <td class="tg-baqh">$y_{2\cdot}$</td>
    <td class="tg-baqh">$\overline{y}_{2\cdot}$</td>
  </tr>
  <tr>
    <td class="tg-amwm">$\vdots$</td>
    <td class="tg-baqh">$\vdots$</td>
    <td class="tg-baqh">$\vdots$</td>
    <td class="tg-baqh">$\cdots$</td>
    <td class="tg-baqh">$\vdots$</td>
    <td class="tg-baqh">$\vdots$</td>
    <td class="tg-baqh">$\vdots$</td>
  </tr>
  <tr>
    <td class="tg-amwm">a</td>
    <td class="tg-baqh">$y_{a1}$</td>
    <td class="tg-baqh">$y_{a2}$</td>
    <td class="tg-baqh">$\cdots$</td>
    <td class="tg-baqh">$y_{an}$</td>
    <td class="tg-baqh">$y_{a\cdot}$</td>
    <td class="tg-baqh">$\overline{y}_{a\cdot}$</td>
  </tr>
</tbody>
</table>

Isto é:

\begin{align}
y_{i\cdot}&=\text{ soma das obs. no trat. i }=\sum_{j=1}^ny_{ij}\\
\overline{y}_{i\cdot}&=\text{ média das obs. no trat. i }=\frac{y_{i\cdot}}{n}\\
y_{\cdot\cdot}&=\text{ soma de todas as obs. }=\sum_{i=1}^a\sum_{j=1}^ny_{ij}\\
\overline{y}_{\cdot\cdot}&=\text{ média de todas as obs.}=\frac{y_{\cdot\cdot}}{N},\text{ em que }N=na
\end{align}

**Decomposição da soma de quadrados total**

> Definimos a soma de quadrados total $SQ_T$ como
\begin{equation}
  SQ_T=\sum_{i=1}^a\sum_{j=1}^n(y_{ij}-\overline{y}_{\cdot\cdot})^2
  (\#eq:sqt)
\end{equation}
e dizemos que tal soma tem $N-1$ graus de liberdade.

É importante notar que $SQ_T$ pode ser utilizada como uma medida de variabilidade total nos dados, uma vez que a variância amostral pode ser estimada por 
$$S^2=\frac{\sum_{i=1}^a\sum_{j=1}^n(y_{ij}-\overline{y}_{\cdot\cdot})^2}{N-1}=\frac{SQ_T}{N-1}$$

Vamos decompor $SQ_T$:
\begin{equation}
\begin{split}
  \sum_{i=1}^a\sum_{j=1}^n(y_{ij}-\overline{y}_{\cdot\cdot})^2&=&
    \sum_{i=1}^a\sum_{j=1}^n\left[(\overline{y}_{i\cdot}-\overline{y}_{\cdot\cdot})+(y_{ij}-\overline{y}_{i\cdot})\right]^2\\
    &=&\sum_{i=1}^a\sum_{j=1}^n(\overline{y}_{i\cdot}-\overline{y}_{\cdot\cdot})^2+\sum_{i=1}^a\sum_{j=1}^n(y_{ij}-\overline{y}_{i\cdot})^2\\
    &&+\sum_{i=1}^a\sum_{j=1}^n2(\overline{y}_{i\cdot}-\overline{y}_{\cdot\cdot})(y_{ij}-\overline{y}_{i\cdot})\\
    &=&n\sum_{i=1}^a(\overline{y}_{i\cdot}-\overline{y}_{\cdot\cdot})^2+\sum_{i=1}^a\sum_{j=1}^n(y_{ij}-\overline{y}_{i\cdot})^2
\end{split}
(\#eq:decompSQ)
\end{equation} 

- na primeira igualdade, somamos e subtraímos $\overline{y}_{i\cdot}$
- da primeira para a segunda linha, desenvolvemos o quadrado
- da segunda para a última linha, o termo $(\overline{y}_{i\cdot}-\overline{y}_{\cdot\cdot})$ não depende de $j$ e podemos somar em $j$, obtendo $n(\overline{y}_{i\cdot}-\overline{y}_{\cdot\cdot})$
- ainda da segunda para a última linha, o último termo é igual a zero, como mostramos a seguir:
\begin{align}
\sum_{i=1}^a\sum_{j=1}^n2(\overline{y}_{i\cdot}-\overline{y}_{\cdot\cdot})(y_{ij}-\overline{y}_{i\cdot}) &=                 2\sum_{i=1}^a(\overline{y}_{i\cdot}-\overline{y}_{\cdot\cdot})\sum_{j=1}^n(y_{ij}-\overline{y}_{i\cdot})\\
    &=2\sum_{i=1}^a\left\{(\overline{y}_{i\cdot}-\overline{y}_{\cdot\cdot})\left[\sum_{j=1}^ny_{ij}-\sum_{j=1}^n\overline{y}_{i\cdot})\right]\right\}\\
    &=2\sum_{i=1}^a\left\{(\overline{y}_{i\cdot}-\overline{y}_{\cdot\cdot})\left[y_{i\cdot}-n\overline{y}_{i\cdot}\right]\right\}\\
    &=2\sum_{i=1}^a\left\{(\overline{y}_{i\cdot}-\overline{y}_{\cdot\cdot})\left[y_{i\cdot}-y_{i\cdot}\right]\right\}=0
\end{align}

A decomposição da soma de quadrados total em \@ref(eq:decompSQ) pode ser escrita por
\begin{equation}
    SQ_T=SQ_{trat}+SQ_{E}
    (\#eq:fundanova)
\end{equation}
em que

- $SQ_{trat}=n\sum_i(\overline{y}_{i\cdot}-\overline{y}_{\cdot\cdot})^2$
- $SQ_E=\sum_i\sum_j(y_{ij}-\overline{y}_{i\cdot})^2$


