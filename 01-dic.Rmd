---
output: html_document
editor_options: 
  chunk_output_type: console
---
# Delineamento Inteiramente Casualizado {#dic}

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

#libraries
library(kableExtra)
library(tidyverse)
```

O *delineamento inteiramente casualizado (DIC)*, como visto anteriormente, é preferido quando as unidades experimentais são homogêneas entre si em suas principais características.

Tal delineamento se dá quando os tratamentos (ou níveis de um fator) são distribuídos **totalmente ao acaso** dentre as unidades experimentais.

Veremos adiante que há diferentes esquemas para se construir tratamentos, como em experimentos fatoriais e em parcelas subdivididas, porém, neste capítulo, trabalhamos apenas com um fator.

::: {.example #dic} 
_Temos $N=9$ sementes de feijão e $a=3$ níveis de irrigação (A, B, C) e iremos medir o peso em gramas da planta, após determinado tempo._

_O DIC pode ser construido enumerando as sementes de 1 a 9 e sorteando aleatoriamente os tratamentos._

_É possível realizar este sorteio no R de diferentes maneiras. Uma delas é através da função `sample`._
```{r, include=FALSE}
set.seed(321)
```
```{r, results='hide'}
N=9 #n. de unidades experimentais
a=3 #n. de tratamentos
n=3 #n. de repetições
sorteio <- sample(x=rep(LETTERS[1:a],n), size=N, replace=F)
print(data.frame("semente"=1:N,"tratamento"=sorteio))
```
```{r, echo=FALSE}
tab <- tibble("semente"=1:N, "tratamento"=sorteio)
kable(tab, align='c')
```

_Neste exemplo, a pergunta que surge é: existe algum nível de irrigação (tratamento) que é melhor do que os demais? Em outras palavras: os tratamentos são diferentes entre si?_

_Estatisticamente falando, estamos estabelecendo hipóteses nula e alternativa:_
\begin{align*}
H_0: & \mu_1=\mu_2=\mu_3\\
H_1: & \mu_1\neq \mu_2 \text{ ou }\mu_1\neq \mu_3 \text{ ou }\mu_2\neq \mu_3
\end{align*}
:::

Sob alguns pressupostos, hipóteses deste tipo podem ser testadas utilizando a **análise de variância**, denominada **ANOVA** (do inglês: **an**alysis **o**f **va**riance), que discutimos a seguir.



<!-- ------------------------------------------------------------ -->



## ANOVA

Suponha que temos:

- $a$ tratamentos (ou níveis de um fator)
- $n$ repetições em cada tratamento
- $N=na$ unidades experimentais,
ou seja, estamos supondo que o DIC seja balanceado (mesmo número de repetições em cada tratamento)

<!-- ----------------------------------------------- -->

### Modelo estatístico (médias)

Um modelo estatístico tem como objetivo descrever matematicamente um fenômeno aleatório do mundo real. Com isso, há suposições que são consideradas, uma vez que se trata de uma aproximação matemática da realidade.

"A realidade é muito mais complexa do que qualquer modelo matemático."

> O **modelo estatístico do DIC** é escrito por:
\begin{equation}
  y_{ij}=\mu_i+\epsilon_{ij}
  (\#eq:modelodic)
\end{equation}
em que:
> 
- $i$ é o índice do tratamento, variando em $1, 2, ..., a$
- $j$ é o índice da repetição em cada tratamento, variando em $1, 2, ..., n$
- $y_{ij}$ é a observação $j$ do tratamento $i$ da variável resposta $y$
- $\mu_i$ é a média (populacional) do tratamento $i$
- $\epsilon_{ij}$ é o  erro aleatório da observação $j$ do tratamento $i$ (incorpora todas as fontes de variação que vão além da variação entre os tratamentos)

Este modelo nos diz que cada observação é igual a média populacional do respectivo tratamento mais um erro aleatório individual. Ou seja, na perspectiva *frequentista* estamos considerando que $\mu_i$ é uma quantidade numérica fixa da população, a "verdadeira média", porém, por se tratar de um **parâmetro**, é desconhecida e não observável.

O componente aleatório deste modelo é o erro $\epsilon_{ij}$, que é individual, i.e. para cada observação $j$ do tratamento $i$. 

::: {.example}

_Utilizando o Exemplo \@ref(exm:dic), vamos supor, hipoteticamente, que você consultou um oráculo e sabe as médias populacionais dos $a=3$ níveis de irrigação. Considere que são:_
\begin{align}
\mu_1=30\\
\mu_2=40\\
\mu_3=50
\end{align}

_Se observamos as $n=3$ repetições no tratamento $1$ como: $y_{11}=33, y_{12}=31, y_{13}=25$; então, a partir do modelo da Equação \@ref(eq:modelodic), temos que:_
\begin{align}
y_{11}=\mu_1+\epsilon_{11} & \Leftrightarrow  33=30+(-3)\\
y_{12}=\mu_1+\epsilon_{12} & \Leftrightarrow  31=30+1\\
y_{13}=\mu_1+\epsilon_{13} & \Leftrightarrow  25=30+(-5)
\end{align}

_Note que, as médias populacionais, na prática, são desconhecidas. Temos acesso apenas as observações $y_{ij}$ e um dos objetivos da **inferência estatística** é, a partir das observações, estimar as médias populacionais. Uma estimativa "natural" para a média populacional é a média amostral._

_Os erros aleatórios também não são observáveis, uma vez que $\epsilon_{ij}=y_{ij}-\mu_i$. No exemplo, $\epsilon_{11}=-3, \epsilon_{12}=1 \text{ e } \epsilon_{13}=-5$._

:::

<!-- ----------------------------------------------- -->

### Pressupostos {#pressupostos}

Para dar seguimento com as análises estatísticas com a ANOVA, precisamos fazer algumas suposições com relação ao modelo estatístico apresentado, que são razoáveis em grande parte das aplicações.

A principal suposição é que:
$$\epsilon_{ij}\overset{ind}{\sim}N(0, \sigma^2)$$
em que $i=1, 2, ..., a; j=1, 2, ..., n.$ Em outras palavras:

1) **Os erros têm média zero**, i.e. $E(\epsilon_{ij})=0.$ Este pressuposto é relativamente intuitivo: as observações da variável resposta $y$ no tratamento $i$ são aleatórias em torno da respectiva média. 
2) **Os erros têm distribuição normal**. Este pressuposto requer que a variável resposta seja aleatória com distribuição normal. O modelo estatístico nos diz que $y_{ij}=\mu_i+\epsilon_{ij}$ e como $\epsilon$ é normal, então $y$ também é. Logo, aplicar a ANOVA requer que a variável resposta $y$ seja normal. Isto se aplica a inúmeros exemplos e geralmente a variável resposta deve ser contínua, simétrica, com uma variabilidade razoável (sem muitos empates). Comprimento e peso são exemplo clássicos de aplicações.  Veremos como verificar os pressupostos em seção subsequente.
3) **Os erros têm variâncias iguais** para todos os tratamentos, i.e. $\sigma^2_1=\sigma^2_1=\cdots =\sigma^2_a=\sigma^2$. Este pressuposto leva o nome de **homocedasticidade** (homogeneidade das variâncias).
4) **Os erros são independentes**, i.e. as unidades experimentais devem ser independentes entre si. Em outras palavras, a observação de uma unidade não está associada a observação de outra unidade qualquer.

A suposição acima poderia ser escrita por:
$$y_{ij}\overset{ind}{\sim}N(\mu_i, \sigma^2)$$
em que $i=1, 2, ..., a; j=1, 2, ..., n,$ uma vez que
\begin{align}
E(y_{ij})&=E(\mu_i+\epsilon_{ij})=E(\mu_i)+E(\epsilon_{ij})=\mu_i+0=\mu_i\\
var(y_{ij})&=var(\mu_i+\epsilon_{ij})=var(\mu_i)+var(\epsilon_{ij})=0+\sigma^2=\sigma^2
\end{align}

<!-- ----------------------------------------------- -->

### Modelo alternativo (efeitos)

Uma maneira alternativa bastante utilizada e também intuitiva é o modelo de efeitos, definido abaixo.

> O **modelo estatístico de efeitos do DIC** pode ser escrito por:
\begin{equation}
  y_{ij}=\mu+\tau_i+\epsilon_{ij}
  (\#eq:modelodic2)
\end{equation}
em que i=1,2, ..., a; j=1, 2, ..., n; $y_{ij}$ e $\epsilon_{ij}$ são idênticos ao modelo de médias \@ref(eq:modelodic); e:
> 
- $\mu$ é uma média (populacional) global;
- $\tau_i$ é o efeito do tratamento $i$ (que pode ser positivo, negativo ou nulo).

Este modelo é análogo ao modelo de médias, mas pode trazer interpretações diferentes:

- $\mu$ representa uma média geral, independente do tratamento
- a média do tratamento $i$ pode ser escrita por $\mu_i=\mu+\tau_i$
- o efeito $\tau_i$ é o que possivelmente diferencia a média de um tratamento do outro
- se o efeito de $\tau_i$ é positivo, a média do tratamento $i$ está acima da média global; caso seja negativo, a média $\mu_i$ está abaixo de $\mu$; caso o efeito seja nulo, a média do tratamento é igual a média global
- se todos os efeitos são nulos, então $\mu_i=\mu, i=1, 2, ..., a$, ou seja, $\mu_1=\mu_2=\cdots \mu_a=\mu$
- os efeitos $\tau_i$ também são parâmetros e, portanto, temos interesse em fazer inferência, uma vez que são reponsáveis por diferenciar um tratamento do outro
- é razoável considerar que $\tau_1+\tau_2+\cdots =\tau_a=0$, i.e. a soma dos efeitos é nula. Isto faz com que a média global $\mu$ seja uma média das médias populacionais (muita média em uma mesma frase, o que pode ser confuso), ou seja:
$$\frac{1}{a}\sum_{i=1}^a\mu_i=\frac{1}{a}\sum_{i=1}^a(\mu+\tau_i)=\frac{1}{a} \left( \sum_{i=1}^a\mu+\sum_{i=1}^a\tau_i \right) =\frac{1}{a}a\mu+0=\mu$$

Tanto o modelo de médias quanto o modelo de efeitos são conhecidos como **ANOVA _ONE-WAY_** ou como **ANOVA DE FATOR ÚNICO**.

<!-- ----------------------------------------------- -->

### Hipóteses

O modelo de médias nos diz que $y_{ij}=\mu_i+\epsilon_{ij}$. Os parâmetros que desejamos fazer inferência são as médias de cada tratamento. A hipótese a ser testada pela ANOVA é:
\begin{equation}
\begin{split}
H_0: & \mu_1=\mu_2=\cdots =\mu_a\\
H_1: & \mu_i\neq \mu_j, \text{ para algum } i\neq j
\end{split}
(\#eq:hipanova)
\end{equation}

Note que, a hipótese alternativa nos diz que basta uma das médias ser diferente das demais que $H_0$ é falsa.

Ao utilizarmos o modelo de médias, note que:
\begin{align}
\mu_1=\mu_2=\cdots =\mu_a &\Leftrightarrow \mu+\tau_1=\mu+\tau_2=\cdots =\mu+\tau_a\\
&\Leftrightarrow \tau_1=\tau_2=\cdots =\tau_a\\
&\Leftrightarrow \tau_1=\tau_2=\cdots =\tau_a=0
\end{align}
Note que a terceira linha desta relação vem do fato que vimos anteriormente que $\tau_1+\tau_2+\cdots +\tau_a=0$ e se $\tau_1=\tau_2=\cdots =\tau_a$, a única possibilidade é que sejam todos iguais a zero.

Dado isso, as hipóteses dadas pela Equação \@ref(eq:hipanova) são equivalentes a:
\begin{equation}
\begin{split}
H_0: & \tau_1=\tau_2=\cdots =\tau_a=0\\
H_1: & \tau_i\neq 0, \text{ para algum } i
\end{split}
\end{equation}
Note que, basta que algum $\tau_i$ seja diferente de zero para que $H_0$ seja falsa.

<!-- ----------------------------------------------- -->

### Por que analisar variância para comparar médias?

Quando temos apenas dois tratamentos, a hipótese nula a ser testada é $H_0: \mu_1=\mu_2$. 
Sob o pressuposto de normalidade, podemos testar tal hipótese com o teste t e não precisamos da ANOVA.

O teste t utiliza como estatística de teste, considerando tamanhos amostrais iguais ($n_1=n_2$) e variâncias iguais ($\sigma^2_1=\sigma^2_2$), a seguinte:
$$t=\frac{\bar{y}_1-\bar{y}_2}{\sqrt{(S^2_1+S^2_2)/n}}$$
em que:

- t tem distribuição t-Student com $2n-2$ graus de liberdade
- $\bar{y}_1$ e $\bar{y_2}$ são as médias amostrais dos tratamentos 1 e 2, respectivamente
- $S_1^2$ e $S_2^2$ são as variâncias amostrais dos tratamentos 1 e 2, respectivamente

O importante neste momento é notar que o valor absoluto da estatística $t$ mede uma distância padronizada (pelo erro padrão $\sqrt{(S^2_1+S^2_2)/n}$) entre as médias amostrais. Em resumo, se $|t|$ for "muito" diferente de zero, isso significa que $\bar y_1$ está "muito" distante de $\bar y_2$, trazendo evidência contra $H_0$. Note que, com um nível de significância estipulado, determinamos o quantil (t tabelado) que nos dá um ponto de corte para considerar o que é $|t|$ ser "muito" diferente de zero, ou seja, se $|t| > t_{tab}$, temos evidência o suficiente para rejeitar $H_0$.

A pergunta que poderia surgir é, é possível medir uma "distância" entre 3 médias de tratamentos para concluir se há evidências o suficiente para rejeitar $H_0:\mu_1=\mu_2=\mu_3$?

A resposta para esta pergunta não é tão trivial, mas está em analisar as variâncias. Considere o seguinte exemplo, para compreender o porque analisar variâncias é útil para comparar médias.

::: {.example} 
<i>
Considere dois cenários, ambos com $a=4$ tratamentos e $n=10$ repetições em cada tratamento, totalizando $N=40$ unidades experimentais.

Vamos simular dados para o cenário A e B, seguindo os pressupostos da subseção [Pressupostos], em que:

- no cenário A há diferença entre as médias;
- no cenário B **não** há diferença entre as médias.

Os dados em ambos os cenários estão representados nos gráficos de dispersão abaixo.

(ref:foo-1) Gráfico de dispersão dos cenários A e B, respectivamente. O ponto vermelho representa a média amostral em cada tratamento. A última coluna representa todos os dados, independente do tratamento.

```{r foo-1, echo=FALSE, fig.cap='(ref:foo-1)'}
set.seed(2468)
n <- 10;a <- 4
trat <- 1:a |> rep(n) |> sort()
total <- rep(5,n*a)
trat <- c(trat,total)

m1 <- 10;m2 <- 20;m3 <- 30;m4 <- 40
y1 <- rnorm(n, m1, 2);y2 <- rnorm(n, m2, 2)
y3 <- rnorm(n, m3, 2);y4 <- rnorm(n, m4, 2)
y <- rep(c(y1,y2,y3,y4),2)
d1 <- tibble(y,trat)

m <- 25
w1 <- rnorm(n, m, 2);w2 <- rnorm(n, m, 2)
w3 <- rnorm(n, m, 2);w4 <- rnorm(n, m, 2)
w <- rep(c(w1,w2,w3,w4),2)
d2 <- tibble(w,trat)

p1 <- d1 |> 
  ggplot(aes(x=trat, y=y)) + 
  geom_point(shape=4) +
  stat_summary(
    geom = "point",
    fun = "mean",
    col = "red",
    size = 2,
    shape = 19
  ) +
  labs(title="Cenário A",
       x="Tratamento", 
       y="Variável Resposta") +
  theme(axis.text.y = element_blank())+
  scale_x_continuous(breaks=1:5,
                   labels=c("Trat 1","Trat 2","Trat 3",
                            "Trat 4","Total"))

p2 <- d2 |> 
  ggplot(aes(x=trat, y=w)) + 
  geom_point(shape=4) +
  stat_summary(
    geom = "point",
    fun = "mean",
    col = "red",
    size = 2,
    shape = 19
  ) +
  labs(title="Cenário B",
       x="Tratamento", 
       y="Variável Resposta") +
  theme(axis.text.y = element_blank())+
  scale_x_continuous(breaks=1:5,
                   labels=c("Trat 1","Trat 2","Trat 3",
                            "Trat 4","Total"))

gridExtra::grid.arrange(p1, p2, ncol=2)
```

Podemos ver na Figura \@ref(fig:foo-1) que de fato o cenário A é diferente do B no que diz respeito às médias; no cenário A as médias amostrais dos tratamentos de 1 a 4 (primeiras 4 colunas) são bem diferentes e no cenário B são próximas. 

Mas observe a dispersão (variância) em cada um dos 4 tratamentos. Em ambos os cenários as dispersões entre os tratamentos são similares entre si. Agora observe a dispersão do total (última coluna):

- no cenário A, as dispersões dos tratamentos são **diferentes** da dispersão total
- no cenário B, as dispersões dos tratamentos são **similares**  da dispersão total

Isso nos leva a crer na seguinte afirmação:

> se as variâncias dos tratamentos são diferentes da variância total dos dados, então as médias são diferentes entre si.

Vamos colocar em termos numéricos estas diferenças. As variâncias amostrais de ambos os cenários são organizadas na tabela abaixo.
```{r echo=FALSE}
vary <- d1 |> group_by(trat) |> summarise(sd(y)) |> select(2) |> as_vector()
varw <- d2 |> group_by(trat) |> summarise(sd(w)) |> select(2) |> as_vector()

tab <- rbind(t(vary),t(varw))
colnames(tab) <- c("$S^2_1$","$S^2_2$","$S^2_3$",
                   "$S^2_4$","$S^2_{Total}$")
rownames(tab) <- c('Cenário A', 'Cenário B')
kable(tab, digits=2)
```

Ao analisar as primeiras 4 colunas (tratamentos) com a última (total), confirmamos que:

- as variâncias dos tratamentos são similares entre si (o que, vale ressaltar, nos leva a crer que o pressuposto de homocedasticidade é válido)
- as variâncias dos tratamentos são diferentes da variância total no cenário A, mas similar no cenário B

Podemos mensurar esta diferença, fazendo uma variância média dos tratamentos e comparar com a total. Considere a variância média como:
$$\overline{S^2}=\frac{1}{a}\sum_{i=1}^aS^2_i$$
e podemos considerar o ganho relativo na variância, obtido ao se considerar os tratamentos, isto é: 
$$R^2=\frac{S^2_{Total}-\overline{S^2}}{S^2_{Total}}$$
Em outras palavras, o $R^2$ mede o quanto a variância total reduziu quando estamos considerando o tratamento que cada observação pertence. Não precisamos interpretá-lo a fundo agora, até porque construiremos outra medida que chamaremos de $F$. A medida $R^2$ é conhecida na Estatística e leva o nome de coeficiente de determinação. 

O que precisamos saber no momento é que $0\leq R^2 \leq 1$ e quanto mais próximo de 1, mas diferente são $S^2_{Total}$ e $\overline{S^2}$ e quanto mais próximo de 0, mais próximos são $S^2_{Total}$ e $\overline{S^2}$.

No cenário A, esta medida é igual a `r round(1-(mean(tab[1,1:4])/tab[1,5]),1)` e no cenário B é igual a `r round(1-(mean(tab[2,1:4])/tab[2,5]),1)`. Podemos interpretar da seguinte maneira:

- no cenário A, 80% da variabilidade dos dados foi explicada pelos tratamentos, tornando os tratamentos um aspecto importante para explicar a variável resposta
- no cenário B, 0% da variabilidade dos dados foi explicada pelos tratamenos, o que mostra a irrelevância dos tratamentos para explicar a variável respota

Em subseção subsequente, construímos uma medida parecida com esta razão que terá distribuição F e, assim, podemos utilizar o teste F para analisar tais variâncias e concluir se há evidências favoráveis ou contrárias à igualdade das médias.
</i>
:::

