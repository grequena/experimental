[["dic.html", "Capítulo 1 Delineamento Inteiramente Casualizado 1.1 ANOVA", " Capítulo 1 Delineamento Inteiramente Casualizado O delineamento inteiramente casualizado (DIC), como visto anteriormente, é preferido quando as unidades experimentais são homogêneas entre si em suas principais características. Tal delineamento se dá quando os tratamentos (ou níveis de um fator) são distribuídos totalmente ao acaso dentre as unidades experimentais. Veremos adiante que há diferentes esquemas para se construir tratamentos, como em experimentos fatoriais e em parcelas subdivididas, porém, neste capítulo, trabalhamos apenas com um fator. Exemplo 1.1 Temos \\(N=9\\) sementes de feijão e \\(a=3\\) níveis de irrigação (A, B, C) e iremos medir o peso em gramas da planta, após determinado tempo. O DIC pode ser construido enumerando as sementes de 1 a 9 e sorteando aleatoriamente os tratamentos. É possível realizar este sorteio no R de diferentes maneiras. Uma delas é através da função sample. N=9 #n. de unidades experimentais a=3 #n. de tratamentos n=3 #n. de repetições sorteio &lt;- sample(x=rep(LETTERS[1:a],n), size=N, replace=F) print(data.frame(&quot;semente&quot;=1:N,&quot;tratamento&quot;=sorteio)) semente tratamento 1 C 2 B 3 B 4 A 5 A 6 A 7 B 8 C 9 C Neste exemplo, a pergunta que surge é: existe algum nível de irrigação (tratamento) que é melhor do que os demais? Em outras palavras: os tratamentos são diferentes entre si? Estatisticamente falando, estamos estabelecendo hipóteses nula e alternativa: \\[\\begin{align*} H_0: &amp; \\mu_1=\\mu_2=\\mu_3\\\\ H_1: &amp; \\mu_1\\neq \\mu_2 \\text{ ou }\\mu_1\\neq \\mu_3 \\text{ ou }\\mu_2\\neq \\mu_3 \\end{align*}\\] Sob alguns pressupostos, hipóteses deste tipo podem ser testadas utilizando a análise de variância, denominada ANOVA (do inglês: analysis of variance), que discutimos a seguir. 1.1 ANOVA Suponha que temos: \\(a\\) tratamentos (ou níveis de um fator) \\(n\\) repetições em cada tratamento \\(N=na\\) unidades experimentais, ou seja, estamos supondo que o DIC seja balanceado (mesmo número de repetições em cada tratamento) 1.1.1 Modelo estatístico (médias) Um modelo estatístico tem como objetivo descrever matematicamente um fenômeno aleatório do mundo real. Com isso, há suposições que são consideradas, uma vez que se trata de uma aproximação matemática da realidade. “A realidade é muito mais complexa do que qualquer modelo matemático.” O modelo estatístico do DIC é escrito por: \\[\\begin{equation} y_{ij}=\\mu_i+\\epsilon_{ij} \\tag{1.1} \\end{equation}\\] em que: \\(i\\) é o índice do tratamento, variando em \\(1, 2, ..., a\\) \\(j\\) é o índice da repetição em cada tratamento, variando em \\(1, 2, ..., n\\) \\(y_{ij}\\) é a observação \\(j\\) do tratamento \\(i\\) da variável resposta \\(y\\) \\(\\mu_i\\) é a média (populacional) do tratamento \\(i\\) \\(\\epsilon_{ij}\\) é o erro aleatório da observação \\(j\\) do tratamento \\(i\\) (incorpora todas as fontes de variação que vão além da variação entre os tratamentos) Este modelo nos diz que cada observação é igual a média populacional do respectivo tratamento mais um erro aleatório individual. Ou seja, na perspectiva frequentista estamos considerando que \\(\\mu_i\\) é uma quantidade numérica fixa da população, a “verdadeira média”, porém, por se tratar de um parâmetro, é desconhecida e não observável. O componente aleatório deste modelo é o erro \\(\\epsilon_{ij}\\), que é individual, i.e. para cada observação \\(j\\) do tratamento \\(i\\). Exemplo 1.2 Utilizando o Exemplo 1.1, vamos supor, hipoteticamente, que você consultou um oráculo e sabe as médias populacionais dos \\(a=3\\) níveis de irrigação. Considere que são: \\[\\begin{align} \\mu_1=30\\\\ \\mu_2=40\\\\ \\mu_3=50 \\end{align}\\] Se observamos as \\(n=3\\) repetições no tratamento \\(1\\) como: \\(y_{11}=33, y_{12}=31, y_{13}=25\\); então, a partir do modelo da Equação (1.1), temos que: \\[\\begin{align} y_{11}=\\mu_1+\\epsilon_{11} &amp; \\Leftrightarrow 33=30+(-3)\\\\ y_{12}=\\mu_1+\\epsilon_{12} &amp; \\Leftrightarrow 31=30+1\\\\ y_{13}=\\mu_1+\\epsilon_{13} &amp; \\Leftrightarrow 25=30+(-5) \\end{align}\\] Note que, as médias populacionais, na prática, são desconhecidas. Temos acesso apenas as observações \\(y_{ij}\\) e um dos objetivos da inferência estatística é, a partir das observações, estimar as médias populacionais. Uma estimativa “natural” para a média populacional é a média amostral. Os erros aleatórios também não são observáveis, uma vez que \\(\\epsilon_{ij}=y_{ij}-\\mu_i\\). No exemplo, \\(\\epsilon_{11}=-3, \\epsilon_{12}=1 \\text{ e } \\epsilon_{13}=-5\\). 1.1.2 Pressupostos Para dar seguimento com as análises estatísticas com a ANOVA, precisamos fazer algumas suposições com relação ao modelo estatístico apresentado, que são razoáveis em grande parte das aplicações. A principal suposição é que: \\[\\epsilon_{ij}\\overset{ind}{\\sim}N(0, \\sigma^2)\\] em que \\(i=1, 2, ..., a; j=1, 2, ..., n.\\) Em outras palavras: Os erros têm média zero, i.e. \\(E(\\epsilon_{ij})=0.\\) Este pressuposto é relativamente intuitivo: as observações da variável resposta \\(y\\) no tratamento \\(i\\) são aleatórias em torno da respectiva média. Os erros têm distribuição normal. Este pressuposto requer que a variável resposta seja aleatória com distribuição normal. O modelo estatístico nos diz que \\(y_{ij}=\\mu_i+\\epsilon_{ij}\\) e como \\(\\epsilon\\) é normal, então \\(y\\) também é. Logo, aplicar a ANOVA requer que a variável resposta \\(y\\) seja normal. Isto se aplica a inúmeros exemplos e geralmente a variável resposta deve ser contínua, simétrica, com uma variabilidade razoável (sem muitos empates). Comprimento e peso são exemplo clássicos de aplicações. Veremos como verificar os pressupostos em seção subsequente. Os erros têm variâncias iguais para todos os tratamentos, i.e. \\(\\sigma^2_1=\\sigma^2_1=\\cdots =\\sigma^2_a=\\sigma^2\\). Este pressuposto leva o nome de homocedasticidade (homogeneidade das variâncias). Os erros são independentes, i.e. as unidades experimentais devem ser independentes entre si. Em outras palavras, a observação de uma unidade não está associada a observação de outra unidade qualquer. A suposição acima poderia ser escrita por: \\[y_{ij}\\overset{ind}{\\sim}N(\\mu_i, \\sigma^2)\\] em que \\(i=1, 2, ..., a; j=1, 2, ..., n,\\) uma vez que \\[\\begin{align} E(y_{ij})&amp;=E(\\mu_i+\\epsilon_{ij})=E(\\mu_i)+E(\\epsilon_{ij})=\\mu_i+0=\\mu_i\\\\ var(y_{ij})&amp;=var(\\mu_i+\\epsilon_{ij})=var(\\mu_i)+var(\\epsilon_{ij})=0+\\sigma^2=\\sigma^2 \\end{align}\\] 1.1.3 Modelo alternativo (efeitos) Uma maneira alternativa bastante utilizada e também intuitiva é o modelo de efeitos, definido abaixo. O modelo estatístico de efeitos do DIC pode ser escrito por: \\[\\begin{equation} y_{ij}=\\mu+\\tau_i+\\epsilon_{ij} \\tag{1.2} \\end{equation}\\] em que i=1,2, …, a; j=1, 2, …, n; \\(y_{ij}\\) e \\(\\epsilon_{ij}\\) são idênticos ao modelo de médias (1.1); e: \\(\\mu\\) é uma média (populacional) global; \\(\\tau_i\\) é o efeito do tratamento \\(i\\) (que pode ser positivo, negativo ou nulo). Este modelo é análogo ao modelo de médias, mas pode trazer interpretações diferentes: \\(\\mu\\) representa uma média geral, independente do tratamento a média do tratamento \\(i\\) pode ser escrita por \\(\\mu_i=\\mu+\\tau_i\\) o efeito \\(\\tau_i\\) é o que possivelmente diferencia a média de um tratamento do outro se o efeito de \\(\\tau_i\\) é positivo, a média do tratamento \\(i\\) está acima da média global; caso seja negativo, a média \\(\\mu_i\\) está abaixo de \\(\\mu\\); caso o efeito seja nulo, a média do tratamento é igual a média global se todos os efeitos são nulos, então \\(\\mu_i=\\mu, i=1, 2, ..., a\\), ou seja, \\(\\mu_1=\\mu_2=\\cdots \\mu_a=\\mu\\) os efeitos \\(\\tau_i\\) também são parâmetros e, portanto, temos interesse em fazer inferência, uma vez que são reponsáveis por diferenciar um tratamento do outro é razoável considerar que \\(\\tau_1+\\tau_2+\\cdots =\\tau_a=0\\), i.e. a soma dos efeitos é nula. Isto faz com que a média global \\(\\mu\\) seja uma média das médias populacionais (muita média em uma mesma frase, o que pode ser confuso), ou seja: \\[\\frac{1}{a}\\sum_{i=1}^a\\mu_i=\\frac{1}{a}\\sum_{i=1}^a(\\mu+\\tau_i)=\\frac{1}{a} \\left( \\sum_{i=1}^a\\mu+\\sum_{i=1}^a\\tau_i \\right) =\\frac{1}{a}a\\mu+0=\\mu\\] Tanto o modelo de médias quanto o modelo de efeitos são conhecidos como ANOVA ONE-WAY ou como ANOVA DE FATOR ÚNICO. 1.1.4 Hipóteses O modelo de médias nos diz que \\(y_{ij}=\\mu_i+\\epsilon_{ij}\\). Os parâmetros que desejamos fazer inferência são as médias de cada tratamento. A hipótese a ser testada pela ANOVA é: \\[\\begin{equation} \\begin{split} H_0: &amp; \\mu_1=\\mu_2=\\cdots =\\mu_a\\\\ H_1: &amp; \\mu_i\\neq \\mu_j, \\text{ para algum } i\\neq j \\end{split} \\tag{1.3} \\end{equation}\\] Note que, a hipótese alternativa nos diz que basta uma das médias ser diferente das demais que \\(H_0\\) é falsa. Ao utilizarmos o modelo de médias, note que: \\[\\begin{align} \\mu_1=\\mu_2=\\cdots =\\mu_a &amp;\\Leftrightarrow \\mu+\\tau_1=\\mu+\\tau_2=\\cdots =\\mu+\\tau_a\\\\ &amp;\\Leftrightarrow \\tau_1=\\tau_2=\\cdots =\\tau_a\\\\ &amp;\\Leftrightarrow \\tau_1=\\tau_2=\\cdots =\\tau_a=0 \\end{align}\\] Note que a terceira linha desta relação vem do fato que vimos anteriormente que \\(\\tau_1+\\tau_2+\\cdots +\\tau_a=0\\) e se \\(\\tau_1=\\tau_2=\\cdots =\\tau_a\\), a única possibilidade é que sejam todos iguais a zero. Dado isso, as hipóteses dadas pela Equação (1.3) são equivalentes a: \\[\\begin{equation} \\begin{split} H_0: &amp; \\tau_1=\\tau_2=\\cdots =\\tau_a=0\\\\ H_1: &amp; \\tau_i\\neq 0, \\text{ para algum } i \\end{split} \\end{equation}\\] Note que, basta que algum \\(\\tau_i\\) seja diferente de zero para que \\(H_0\\) seja falsa. 1.1.5 Por que analisar variância para comparar médias? Quando temos apenas dois tratamentos, a hipótese nula a ser testada é \\(H_0: \\mu_1=\\mu_2\\). Sob o pressuposto de normalidade, podemos testar tal hipótese com o teste t e não precisamos da ANOVA. O teste t utiliza como estatística de teste, considerando tamanhos amostrais iguais (\\(n_1=n_2\\)) e variâncias iguais (\\(\\sigma^2_1=\\sigma^2_2\\)), a seguinte: \\[t=\\frac{\\bar{y}_1-\\bar{y}_2}{\\sqrt{(S^2_1+S^2_2)/n}}\\] em que: t tem distribuição t-Student com \\(2n-2\\) graus de liberdade \\(\\bar{y}_1\\) e \\(\\bar{y_2}\\) são as médias amostrais dos tratamentos 1 e 2, respectivamente \\(S_1^2\\) e \\(S_2^2\\) são as variâncias amostrais dos tratamentos 1 e 2, respectivamente O importante neste momento é notar que o valor absoluto da estatística \\(t\\) mede uma distância padronizada (pelo erro padrão \\(\\sqrt{(S^2_1+S^2_2)/n}\\)) entre as médias amostrais. Em resumo, se \\(|t|\\) for “muito” diferente de zero, isso significa que \\(\\bar y_1\\) está “muito” distante de \\(\\bar y_2\\), trazendo evidência contra \\(H_0\\). Note que, com um nível de significância estipulado, determinamos o quantil (t tabelado) que nos dá um ponto de corte para considerar o que é \\(|t|\\) ser “muito” diferente de zero, ou seja, se \\(|t| &gt; t_{tab}\\), temos evidência o suficiente para rejeitar \\(H_0\\). A pergunta que poderia surgir é, é possível medir uma “distância” entre 3 médias de tratamentos para concluir se há evidências o suficiente para rejeitar \\(H_0:\\mu_1=\\mu_2=\\mu_3\\)? A resposta para esta pergunta não é tão trivial, mas está na em analisar as variâncias. Considere o seguinte exemplo, para compreender o porque analisar variâncias é útil para comparar médias. Exemplo 1.3 Considere dois cenários, ambos com \\(a=4\\) tratamentos e \\(n=10\\) repetições em cada tratamento, totalizando \\(N=40\\) unidades experimentais. Vamos simular dados para o cenário A e B, seguindo os pressupostos da Subseção Pressupostos, em que: no cenário A há diferença entre as médias; no cenário B não há diferença entre as médias. Os dados em ambos os cenários estão representados nos gráficos de dispersão abaixo. plot(cars) # a scatterplot Figura 1.1: A scatterplot of the data cars using base R graphics. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
